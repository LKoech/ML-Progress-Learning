{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Purpose\n",
    "----------------\n",
    "\n",
    "In this notebook we are going to learn about data leakage and it's effects on the results of a model causing overly positive results that are not in line with the results if the model was placed in the real world.\n",
    "\n",
    "We can define leakage as “when information concerning the ground truth is artifi-\n",
    "cially and unintentionally introduced within the training feature data, or training\n",
    "metadata” as stated by Michael Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "----------------\n",
    "\n",
    "The data we are using is from a publicly available dataset from kaggle. Here's the link to get the dataset:\n",
    "https://www.kaggle.com/datasets/mahad049/job-placement-dataset\n",
    "\n",
    "The data is about job placement of university students. The model is supposed to predict who will get a job placement and not.\n",
    "We will get a score of the prediction and check for ways to mititgate leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| variable        | description                                                                           |\n",
    "|-----------------|---------------------------------------------------------------------------------------|\n",
    "| `id`         | unique identifier for each student         |\n",
    "| `name`          | name of the student.                                   |\n",
    "| `gender`     | gender of student: male or female.                                       |\n",
    "| `degree`        | type of degree: Bachelors.                                                    |\n",
    "| `stream`      | the stream of speciality a student specialized in university: Computer Science, Electrical Engineering, Mechanical Engineering.        |\n",
    "| `college name`  | the name of the university the student undertook their studies.                                                                     |\n",
    "| `placement_status` | wether the student got a job placement or not.                                |\n",
    "| `salary`  | the salary amount per year for each student working with a job placement.                                 |\n",
    "| `gpa`  | the student academic status based on the university gpa grading system .                                                    |\n",
    "| `years_of_experience`     | total number of years working.                                                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup\n",
    "----------------\n",
    "\n",
    "We will start by importing relevant libraries, setting up our notebook, reading in the data, and checking that it was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we used is publicly available from kaggle. Here is the link to gain access to the dataset.\n",
    "\n",
    "It entails students and wether they got a job placement categorizing them according to different characteristics like gender,\n",
    "\n",
    " university, stream and work experience to determine wether each individual got a job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>degree</th>\n",
       "      <th>stream</th>\n",
       "      <th>college_name</th>\n",
       "      <th>placement_status</th>\n",
       "      <th>salary</th>\n",
       "      <th>gpa</th>\n",
       "      <th>years_of_experience</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>60000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Placed</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>58000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily Davis</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>62000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  gender  age      degree                  stream  \\\n",
       "id                                                                     \n",
       "1          John Doe    Male   25  Bachelor's        Computer Science   \n",
       "2        Jane Smith  Female   24  Bachelor's  Electrical Engineering   \n",
       "3   Michael Johnson    Male   26  Bachelor's  Mechanical Engineering   \n",
       "4       Emily Davis  Female   23  Bachelor's  Information Technology   \n",
       "5       David Brown    Male   24  Bachelor's        Computer Science   \n",
       "\n",
       "                             college_name placement_status  salary  gpa  \\\n",
       "id                                                                        \n",
       "1                      Harvard University           Placed   60000  3.7   \n",
       "2   Massachusetts Institute of Technology           Placed   65000  3.6   \n",
       "3                     Stanford University           Placed   58000  3.8   \n",
       "4                         Yale University       Not Placed       0  3.5   \n",
       "5                    Princeton University           Placed   62000  3.9   \n",
       "\n",
       "    years_of_experience  \n",
       "id                       \n",
       "1                   2.0  \n",
       "2                   1.0  \n",
       "3                   3.0  \n",
       "4                   2.0  \n",
       "5                   2.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('job_placement.csv',index_col=\"id\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing Data\n",
    "----------------\n",
    "\n",
    "We explore the data by checking for missing data. \n",
    "\n",
    "We also check the data types for the entires to know how to handle the data if we might require encoding to change non numerical data to numerical data and also how to fill any missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                   0\n",
       "gender                 0\n",
       "age                    0\n",
       "degree                 0\n",
       "stream                 0\n",
       "college_name           0\n",
       "placement_status       0\n",
       "salary                 0\n",
       "gpa                    0\n",
       "years_of_experience    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                    object\n",
       "gender                  object\n",
       "age                      int64\n",
       "degree                  object\n",
       "stream                  object\n",
       "college_name            object\n",
       "placement_status        object\n",
       "salary                   int64\n",
       "gpa                    float64\n",
       "years_of_experience    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why i replaced instead of dropped the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are checking where we have the missing data so that we can understand the other features associated \n",
    "with it and how we  how we can fill it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>degree</th>\n",
       "      <th>stream</th>\n",
       "      <th>college_name</th>\n",
       "      <th>placement_status</th>\n",
       "      <th>salary</th>\n",
       "      <th>gpa</th>\n",
       "      <th>years_of_experience</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, gender, age, degree, stream, college_name, placement_status, salary, gpa, years_of_experience]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rows = df[df.isnull().any(axis=1)]\n",
    "missing_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning data**\n",
    "\n",
    "For our missing data in our dataset we chose to impute the data for the following reasons:\n",
    " - Peserve data since our dataset is quite small.\n",
    " - The area of the missing data is important to analysis because of the size of uour dataset\n",
    "\n",
    "The student associated with the missing data has been placed and has a salary meaning they have some work experience.\n",
    "\n",
    "We get the mean, median and mode of the students who studied Mechanical Engineering as our student to \n",
    "understand the features more and figure out how to fill the missing data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean experience: 2.118181818181818\n",
      "Median experience: 2.0\n",
      "Mode experience: 3.0\n"
     ]
    }
   ],
   "source": [
    "mechanical_engineering_df = df[df['stream'] == 'Mechanical Engineering']\n",
    "mean_experience = mechanical_engineering_df['years_of_experience'].mean()\n",
    "median_experience = mechanical_engineering_df['years_of_experience'].median()\n",
    "mode_experience = mechanical_engineering_df['years_of_experience'].mode()[0]\n",
    "\n",
    "print(\"Mean experience:\", mean_experience)\n",
    "print(\"Median experience:\", median_experience)\n",
    "print(\"Mode experience:\", mode_experience)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we clean the data or replace the missing entry withthe mean of the years of experience for our model to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Fill missing data with pandas\n",
    "\n",
    "We used mode to fill the missing value because it represents the most frequently occuring value in that column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['years_of_experience'].fillna(df[\"years_of_experience\"].mode()[0],inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm the missing data is filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                                         Sophia Johnson\n",
       "gender                                               Female\n",
       "age                                                      24\n",
       "degree                                           Bachelor's\n",
       "stream                               Mechanical Engineering\n",
       "college_name           University of California--Santa Cruz\n",
       "placement_status                                     Placed\n",
       "salary                                                60000\n",
       "gpa                                                     3.7\n",
       "years_of_experience                                     3.0\n",
       "Name: 545, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_545 = df.iloc[544]\n",
    "row_545\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Convert non-numerical data to numerical data**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have to choose the features that will help our model predict wether a student has been placed or not.\n",
    "\n",
    "The features that we will we use; gender, age, stream, gpa, years_of_experience.\n",
    "\n",
    "We are predicting; placement_status of the students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Encoding*\n",
    "\n",
    "We are going to use encoding to change our categorical variables to a numerical value for the machine learning algorithms to understand them.\n",
    "\n",
    "We use OneHotEncoder from the sklearn preprocessing module to helps us handle categorical data in Machine Learning tasks.\n",
    "\n",
    "The idea behind OneHotEncoder is to create a binary vector for each categorical variable.\n",
    "Each binary vector has a length equal to the number of unique categories in the variable.The vector contains all zeros except for a single one at the index corresponding to the category it represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>degree</th>\n",
       "      <th>stream</th>\n",
       "      <th>college_name</th>\n",
       "      <th>placement_status</th>\n",
       "      <th>salary</th>\n",
       "      <th>gpa</th>\n",
       "      <th>years_of_experience</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>John Doe</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>60000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Electrical Engineering</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Placed</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>58000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emily Davis</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Brown</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>62000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  gender  age      degree                  stream  \\\n",
       "id                                                                     \n",
       "1          John Doe    Male   25  Bachelor's        Computer Science   \n",
       "2        Jane Smith  Female   24  Bachelor's  Electrical Engineering   \n",
       "3   Michael Johnson    Male   26  Bachelor's  Mechanical Engineering   \n",
       "4       Emily Davis  Female   23  Bachelor's  Information Technology   \n",
       "5       David Brown    Male   24  Bachelor's        Computer Science   \n",
       "\n",
       "                             college_name placement_status  salary  gpa  \\\n",
       "id                                                                        \n",
       "1                      Harvard University           Placed   60000  3.7   \n",
       "2   Massachusetts Institute of Technology           Placed   65000  3.6   \n",
       "3                     Stanford University           Placed   58000  3.8   \n",
       "4                         Yale University       Not Placed       0  3.5   \n",
       "5                    Princeton University           Placed   62000  3.9   \n",
       "\n",
       "    years_of_experience  \n",
       "id                       \n",
       "1                   2.0  \n",
       "2                   1.0  \n",
       "3                   3.0  \n",
       "4                   2.0  \n",
       "5                   2.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the non numerical data from the features we are going to use are stream and gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 1.0, ..., 60000, 3.7, 2.0],\n",
       "       [1.0, 0.0, 0.0, ..., 65000, 3.6, 1.0],\n",
       "       [0.0, 1.0, 0.0, ..., 58000, 3.8, 3.0],\n",
       "       ...,\n",
       "       [0.0, 1.0, 1.0, ..., 65000, 3.8, 3.0],\n",
       "       [1.0, 0.0, 0.0, ..., 66000, 3.7, 2.0],\n",
       "       [0.0, 1.0, 0.0, ..., 0, 3.6, 1.0]], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import  OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "categorical_features = [\"gender\",\"stream\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                  one_hot,\n",
    "                                  categorical_features)],\n",
    "                                  remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(df)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have encoded our data into numerical values to be interpreted by the machine learning model. Let us see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>John Doe</td>\n",
       "      <td>25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>60000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jane Smith</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>Placed</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Michael Johnson</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>58000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Emily Davis</td>\n",
       "      <td>23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Yale University</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>David Brown</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>Placed</td>\n",
       "      <td>62000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Lucas Taylor</td>\n",
       "      <td>23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University of Washington</td>\n",
       "      <td>Placed</td>\n",
       "      <td>67000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Emma Martinez</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University of California--Berkeley</td>\n",
       "      <td>Placed</td>\n",
       "      <td>66000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Aiden Davis</td>\n",
       "      <td>24</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University of Illinois--Urbana-Champaign</td>\n",
       "      <td>Placed</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Mia Wilson</td>\n",
       "      <td>23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University of Colorado--Boulder</td>\n",
       "      <td>Placed</td>\n",
       "      <td>66000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Jack Garcia</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>University of North Carolina--Chapel Hill</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0    1    2    3    4    5    6                7   8           9   \\\n",
       "0    0.0  1.0  1.0  0.0  0.0  0.0  0.0         John Doe  25  Bachelor's   \n",
       "1    1.0  0.0  0.0  1.0  0.0  0.0  0.0       Jane Smith  24  Bachelor's   \n",
       "2    0.0  1.0  0.0  0.0  0.0  0.0  1.0  Michael Johnson  26  Bachelor's   \n",
       "3    1.0  0.0  0.0  0.0  0.0  1.0  0.0      Emily Davis  23  Bachelor's   \n",
       "4    0.0  1.0  1.0  0.0  0.0  0.0  0.0      David Brown  24  Bachelor's   \n",
       "..   ...  ...  ...  ...  ...  ...  ...              ...  ..         ...   \n",
       "695  0.0  1.0  1.0  0.0  0.0  0.0  0.0     Lucas Taylor  23  Bachelor's   \n",
       "696  1.0  0.0  0.0  0.0  1.0  0.0  0.0    Emma Martinez  26  Bachelor's   \n",
       "697  0.0  1.0  1.0  0.0  0.0  0.0  0.0      Aiden Davis  24  Bachelor's   \n",
       "698  1.0  0.0  0.0  1.0  0.0  0.0  0.0       Mia Wilson  23  Bachelor's   \n",
       "699  0.0  1.0  0.0  0.0  0.0  1.0  0.0      Jack Garcia  26  Bachelor's   \n",
       "\n",
       "                                            10          11     12   13   14  \n",
       "0                           Harvard University      Placed  60000  3.7  2.0  \n",
       "1        Massachusetts Institute of Technology      Placed  65000  3.6  1.0  \n",
       "2                          Stanford University      Placed  58000  3.8  3.0  \n",
       "3                              Yale University  Not Placed      0  3.5  2.0  \n",
       "4                         Princeton University      Placed  62000  3.9  2.0  \n",
       "..                                         ...         ...    ...  ...  ...  \n",
       "695                   University of Washington      Placed  67000  3.8  3.0  \n",
       "696         University of California--Berkeley      Placed  66000  3.9  3.0  \n",
       "697   University of Illinois--Urbana-Champaign      Placed  65000  3.8  3.0  \n",
       "698            University of Colorado--Boulder      Placed  66000  3.7  2.0  \n",
       "699  University of North Carolina--Chapel Hill  Not Placed      0  3.6  1.0  \n",
       "\n",
       "[700 rows x 15 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to drop the data we will not use that when training our model and create a new Dataframe \n",
    "with relevant data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Placed</td>\n",
       "      <td>60000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Placed</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Placed</td>\n",
       "      <td>58000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>Not Placed</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Placed</td>\n",
       "      <td>62000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6   8           11     12   13   14\n",
       "0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  25      Placed  60000  3.7  2.0\n",
       "1  1.0  0.0  0.0  1.0  0.0  0.0  0.0  24      Placed  65000  3.6  1.0\n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  1.0  26      Placed  58000  3.8  3.0\n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  23  Not Placed      0  3.5  2.0\n",
       "4  0.0  1.0  1.0  0.0  0.0  0.0  0.0  24      Placed  62000  3.9  2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=pd.DataFrame(transformed_X)\n",
    "df2.drop([7,9,10],axis =1,inplace=True)\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to encode the placement_status which had been encoded to column 11.\n",
    "\n",
    "We will be using the LabelEncoder class from sklearn.preprocessing to convert categorical data it into numrical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>65000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>58000</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>62000</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6   8   11     12   13   14\n",
       "0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  25   1  60000  3.7  2.0\n",
       "1  1.0  0.0  0.0  1.0  0.0  0.0  0.0  24   1  65000  3.6  1.0\n",
       "2  0.0  1.0  0.0  0.0  0.0  0.0  1.0  26   1  58000  3.8  3.0\n",
       "3  1.0  0.0  0.0  0.0  0.0  1.0  0.0  23   0      0  3.5  2.0\n",
       "4  0.0  1.0  1.0  0.0  0.0  0.0  0.0  24   1  62000  3.9  2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the values in column 11\n",
    "encoder.fit(df2[11])\n",
    "\n",
    "# Transform the values in column 11 using the fitted encoder\n",
    "df2[11] = encoder.transform(df2[11])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Split data into features and labels\n",
    "\n",
    "A feature is a measurable characteristic observed to input into the model to make predictions.\n",
    "\n",
    "A label is the target variable we want to predict. In our case it is Job Placement of the students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   11\n",
       "0   1\n",
       "1   1\n",
       "2   1\n",
       "3   0\n",
       "4   1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into X and Y\n",
    "X = df2.drop([11],axis=1)\n",
    "Y = df2[[11]]\n",
    "\n",
    "\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Convert non-numerical data to numerical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Step 5: Split data into training and test sets\n",
    "\n",
    "We split the encoded data into a training set (80%) and test set (20%). The trainig set is used to evaluate the model while the testing set is used to provide an unbiased evaluation of the model's performance on unseen data.\n",
    "\n",
    "We used the train_test_split function from the sklearn.model_selection module to split our data.\n",
    "We utilised the  random_state parameter in the train_test_split function to set seed for random number generator ensuring random splits reducing bias and generalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42) \n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     11\n",
       "82    1\n",
       "51    1\n",
       "220   0\n",
       "669   1\n",
       "545   0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ms-Echo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Score the model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "_ _ _ _ _ _ _ _ _ \n",
    "\n",
    "What machine learning model are we likey to use with this dataset and Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a classification model because we want to predict the placement status of students which is a categorical variable making this a classification task.\n",
    "\n",
    "Here is a cheatsheet to help in understanding more about this;\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n",
    "_ _ _ _ _ \n",
    "What feature is likely to be a source of leakage and why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3\n",
    "- - - - - - - -\n",
    "This classification problem with the  dataset has achieved a performance score of\n",
    "100% for training data after this experiment. What should your next step be to identify and fix the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4\n",
    "_ _ _ _ _ _ _\n",
    "\n",
    "For the different causes of leakage how can we fix or improve our score to be less optimistic ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. pre-processing before splitting into training/test sets**\n",
    "\n",
    "_ _ _ _ _ _\n",
    "\n",
    "*Solution*\n",
    "\n",
    "We use fit_transform() method of the OneHotEncoder class on the training data because it prevents the model from gaining information from the test data which supposed to be hidden from it. \n",
    "\n",
    "\n",
    "This ensures that the encoding is only done from the training data and not from the test data, preventing data leakage.\n",
    "\n",
    "After learning the encoding from the training data, the same encoder is used to transform the test data using\n",
    "the transform() method. \n",
    "\n",
    "This ensures consistency in the encoding process between the two datasets.\n",
    "\n",
    "By separating the encoding process into two steps (fitting on training data and transforming on test data), we are following the best practice of preventing data leakage and ensuring that the model is evaluated on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df['years_of_experience'].fillna(df[\"years_of_experience\"].mode()[0],inplace=True) \n",
    "\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop(\"placement_status\", axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the encoder on the training set\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set using the same encoder\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Initialize and train your model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "score = model.score(X_test_encoded, Y_test)\n",
    "\n",
    "print(\"Model score: \", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is at 0.992857 it has dropped from 1.0 which is a good sign! We have reduced leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. feature selection before splitting into training/test sets**\n",
    "_ _ _ _ _ _ \n",
    "\n",
    "*Solution*\n",
    "\n",
    "To prevent feature selection from accessing information from the test set during training, you should perform feature selection only on the training data and then apply the same feature selection to the test data.\n",
    "\n",
    "we perform feature selection only on the training data after fitting the model on it. Then, we transform both the training and test sets using the selected features before training and evaluating the model, respectively. This ensures that there's no leakage of information from the test set during feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop([\"placement_status\",\"salary\"], axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the encoder on the training set\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set using the same encoder\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train_encoded, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the SelectFromModel class  which is a Meta-transformer for selecting features based on importance weights.\n",
    "\n",
    "\n",
    "We utilise the estimator parameter which is the base estimator used for feature selection.\n",
    "The .fit method of the SelectFromModel class is called on the training data to fit the underlying estimator on it.\n",
    "\n",
    "The get_support method is called to retrieve a mask of the selected features. This method returns a boolean mask where True indicates the selected features.\n",
    "\n",
    "The training and test sets are transformed using the selected features.This operation selects only the features that were deemed important by the feature selection process.\n",
    "\n",
    "The underlying estimator is then trained on the selected features using the fit method. This step ensures that the model is trained only on the relevant features.\n",
    "\n",
    "Finally we print the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Perform feature selection on the training set\n",
    "selector = SelectFromModel(model, threshold='median')\n",
    "selector.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Get selected features\n",
    "selected_features = selector.get_support()\n",
    "\n",
    "# Transform the training and test set using selected features\n",
    "X_train_selected = X_train_encoded[:, selected_features]\n",
    "X_test_selected = X_test_encoded[:, selected_features]\n",
    "\n",
    "# Train the model on the selected features\n",
    "model.fit(X_train_selected, Y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "score = model.score(X_test_selected, Y_test)\n",
    "\n",
    "print(\"Model score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is at 0.97857 which lower than 1.0 which is an improvement hence we have reduced leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Duplicated data in both test and training sets**\n",
    "_ _ _ _ _ _\n",
    "In this code we remove the duplicated rows from the dataframe we use drop_duplicates() method from pandas. \n",
    "\n",
    "We do this before splitting our datainto training and test sets to ensure our model's performance to reduce overly optimistic performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score:  0.9785714285714285\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import pandas as pd\n",
    "\n",
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop([\"placement_status\",\"salary\"], axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Split your data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the encoder on the training set\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "# Transform the test set using the same encoder\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Score the model on the test data\n",
    "score = model.score(X_test_encoded, Y_test)\n",
    "\n",
    "print(\"Model score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is at 0.992857 which lower than 1.0 which is an improvement hence we have reduced leakage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Temporal leakage**\n",
    "_ _ _ _ _ _ _ \n",
    "\n",
    "Our data has a temporal structure meaning the order of the observations matters and is meaningful.\n",
    "\n",
    "Therefore,  we can perform a time series cross-validation to ensure that the model evaluation does not leak information from the future into the past.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "\n",
    "# Handle missing values\n",
    "df['years_of_experience'].fillna(0, inplace=True)\n",
    "\n",
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop([\"placement_status\",\"salary\"], axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the entire dataset\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TimeSeriesSplit class is initialized with the parameter where n_splits=20 meaning the dataset will be split  into 20 consecutive folds for cross validation.\n",
    "\n",
    "A for loop is used to iterate over each fold generated by the TimeSeriesSplit object. In each iteration, the dataset is split into training and testing sets using the indices obtained from the split() method.\n",
    "\n",
    "We initialized a list called scores to store the accuracy scores of each fold.\n",
    "\n",
    "The training and testing sets for both the features (X_train, X_test) and the target variable (Y_train, Y_test) are extracted from the encoded dataset and the target variable Y. The model is trained on the training data using the fit() method.\n",
    "\n",
    "The model is used to predict the target variable for the testing data using the predict() method.\n",
    "\n",
    "The accuracy of the model is evaluated by comparing the predicted values (Y_pred) with the actual values (Y_test) using the accuracy_score() function from the sklearn.metrics module.\n",
    "\n",
    "After all the folds have been processed, the average model accuracy is calculated by summing up all the scores and dividing by the number of folds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 1.0\n",
      "Average Model Accuracy: 0.9636363636363636\n"
     ]
    }
   ],
   "source": [
    "# Initialize TimeSeriesSplit\n",
    "# You can adjust the number of splits as needed\n",
    "tscv = TimeSeriesSplit(n_splits=20)  \n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in tscv.split(X_encoded):\n",
    "    X_train, X_test = X_encoded[train_index], X_encoded[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Initialize the model\n",
    "    model = RandomForestClassifier()\n",
    "    # Train your model\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    Y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model using accuracy score\n",
    "    score = accuracy_score(Y_test, Y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "\n",
    "print(\"Average Model Accuracy:\", sum(scores) / len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line sum(scores) calculates the sum of all the scores in the list, and len(scores) returns the length of the list, which is the total number of scores. By dividing the sum of scores by the number of scores, you get the average model accuracy.\n",
    "\n",
    "The score is at 0.9606 which is a bit lower than 1.0 hence we have reduced leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below shows k-fold cross-validation. In this case, k is set to 10 (cv=10), which means the validation set is split into 10 equal parts. The model is then trained and evaluated 10 times, each time using a different one of the 10 parts as the validation set and the remaining 9 parts as the training set. The average of the 10 validation scores is then used as the overall validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.90909091 1.         0.90909091 1.         0.81818182 0.8\n",
      " 0.9        0.9        1.         0.9       ]\n",
      "Average cross-validation score:  0.9136363636363637\n",
      "Test score:  0.9904761904761905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop([\"placement_status\", \"salary\"], axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Split your data into training, validation, and test sets\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X, Y, test_size=0.3, random_state=10)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=10)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the encoder on the training set\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "# Transform the validation and test sets using the same encoder\n",
    "X_val_encoded = encoder.transform(X_val)\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "# Initialize and train your model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "# Use cross-validation to evaluate the model\n",
    "scores = cross_val_score(model, X_val_encoded, Y_val, cv=10)\n",
    "\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Average cross-validation score: \", scores.mean())\n",
    "\n",
    "# Score the model on the test data\n",
    "score = model.score(X_test_encoded, Y_test)\n",
    "\n",
    "print(\"Test score: \", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **5. Group leakage**\n",
    " _ _ _ _ _ \n",
    " \n",
    " GroupKFold is used instead of train_test_split. The split method of GroupKFold takes an additional argument groups which is an array-like object that defines the group membership 'stream' for each sample in the data. This ensures that the same group is not represented in both the training and testing sets of any split, preventing group leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Model Accuracy: 0.9715385568619705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "import numpy as np\n",
    "\n",
    "# Handle missing values\n",
    "df['years_of_experience'].fillna(0, inplace=True)\n",
    "\n",
    "# Remove duplicated rows\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Define your features and target\n",
    "X = df.drop([\"placement_status\",\"salary\"], axis=1)\n",
    "Y = df[\"placement_status\"]\n",
    "\n",
    "# Define a mapping for placement status\n",
    "placement_status_mapping = {\"Placed\": 1, \"Not Placed\": 0}\n",
    "\n",
    "# Apply the mapping to the Y series\n",
    "Y = Y.map(placement_status_mapping)\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder on the entire dataset\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Initialize GroupKFold\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "# Assume that 'group_column' is the name of your group column\n",
    "groups = df['stream']\n",
    "\n",
    "scores = []\n",
    "for train_index, test_index in gkf.split(X, Y, groups):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    Y_train, Y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    # Fit and transform the encoder on the training set\n",
    "    X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "    # Transform the test set using the same encoder\n",
    "    X_test_encoded = encoder.transform(X_test)\n",
    "\n",
    "    # Train your model\n",
    "    model.fit(X_train_encoded, Y_train)\n",
    "\n",
    "    # Predict on the test data\n",
    "    Y_pred = model.predict(X_test_encoded)\n",
    "\n",
    "    # Evaluate the model using accuracy score\n",
    "    score = accuracy_score(Y_test, Y_pred)\n",
    "    scores.append(score)\n",
    "\n",
    "print(\"Average Model Accuracy:\", np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is at 0.978327 which is a much better score compared to 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refrences\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
